
  0%|▎                                                                                                                                         | 1/500 [00:01<13:34,  1.63s/it]
Epoch: 1
LOSS: train: 0.189828 grad:0.004852   |   test: 0.153015 grad: 0.004059
Epoch: 2

  0%|▌                                                                                                                                         | 2/500 [00:03<12:37,  1.52s/it]
Epoch: 3

  1%|▊                                                                                                                                         | 3/500 [00:04<12:18,  1.49s/it]
Epoch: 4

  1%|█▍                                                                                                                                        | 5/500 [00:07<12:02,  1.46s/it]
Epoch: 5
LOSS: train: 0.065613 grad:0.003014   |   test: 0.055322 grad: 0.002481
Epoch: 6

  1%|█▋                                                                                                                                        | 6/500 [00:08<11:58,  1.45s/it]
Epoch: 7

  1%|█▉                                                                                                                                        | 7/500 [00:10<12:13,  1.49s/it]
Epoch: 8

  2%|██▍                                                                                                                                       | 9/500 [00:13<12:22,  1.51s/it]
Epoch: 9
LOSS: train: 0.029083 grad:0.002179   |   test: 0.025459 grad: 0.001735
Epoch: 10

  2%|██▋                                                                                                                                      | 10/500 [00:15<12:27,  1.53s/it]
Epoch: 11

  2%|███                                                                                                                                      | 11/500 [00:16<12:20,  1.51s/it]
Epoch: 12

  3%|███▌                                                                                                                                     | 13/500 [00:19<12:11,  1.50s/it]
Epoch: 13
LOSS: train: 0.016528 grad:0.001884   |   test: 0.014745 grad: 0.001527
Epoch: 14

  3%|███▊                                                                                                                                     | 14/500 [00:20<12:10,  1.50s/it]
Epoch: 15

  3%|████                                                                                                                                     | 15/500 [00:22<12:03,  1.49s/it]
Epoch: 16
LOSS: train: 0.012534 grad:0.001853   |   test: 0.011205 grad: 0.001520
Epoch: 17

  3%|████▋                                                                                                                                    | 17/500 [00:25<12:05,  1.50s/it]
Epoch: 18

  4%|████▉                                                                                                                                    | 18/500 [00:27<12:34,  1.57s/it]
Epoch: 19

  4%|█████▏                                                                                                                                   | 19/500 [00:28<12:29,  1.56s/it]
Epoch: 20

  4%|█████▍                                                                                                                                   | 20/500 [00:30<12:35,  1.57s/it]
Epoch: 21
LOSS: train: 0.009324 grad:0.001854   |   test: 0.008464 grad: 0.001540
Epoch: 22

  4%|██████                                                                                                                                   | 22/500 [00:33<12:36,  1.58s/it]
Epoch: 23

  5%|██████▎                                                                                                                                  | 23/500 [00:35<12:27,  1.57s/it]
Epoch: 24

  5%|██████▌                                                                                                                                  | 24/500 [00:37<12:31,  1.58s/it]
Traceback (most recent call last):
  File "/home/denis/Desktop/master/masterthesis15_03-13_09-2024/recap/corrected/mlp_func/main_mlp_vec.py", line 127, in <module>
    loss.backward()
  File "/home/denis/anaconda3/envs/hnn/lib/python3.8/site-packages/torch/_tensor.py", line 488, in backward
    torch.autograd.backward(
  File "/home/denis/anaconda3/envs/hnn/lib/python3.8/site-packages/torch/autograd/__init__.py", line 197, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
  File "/home/denis/anaconda3/envs/hnn/lib/python3.8/site-packages/torch/autograd/function.py", line 267, in apply
    return user_fn(self, *args)
  File "/home/denis/anaconda3/envs/hnn/lib/python3.8/site-packages/torchdiffeq/_impl/adjoint.py", line 126, in backward
    aug_state = odeint(
  File "/home/denis/anaconda3/envs/hnn/lib/python3.8/site-packages/torchdiffeq/_impl/odeint.py", line 77, in odeint
    solution = solver.integrate(t)
  File "/home/denis/anaconda3/envs/hnn/lib/python3.8/site-packages/torchdiffeq/_impl/solvers.py", line 108, in integrate
    while j < len(t) and t1 >= t[j]:
KeyboardInterrupt