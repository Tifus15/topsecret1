DEBUG MODE: False
Config file content:
{'model': 'GCN', 'sob': True, 'sob_a': 0.01, 'a': 0.01, 'opti': 'adamW', 'reg': 'none', 'loss': 'Huber', 'acts': ['tanh', None], 'epochs': 10, 'modelsize': 128, 'batchsize': 256, 'timesize': 32, 'lr': 0.0005, 'split': 0.9, 'device': 'cpu', 'single': False}
/work/scratch/da35hevy/server-graph-models/master
6body
10
torch.Size([512, 1000, 6, 1])
torch.Size([512, 1000, 6, 4])
torch.Size([512, 1000, 6, 4])
[0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5]
[0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5]
torch.Size([512, 999, 6, 9])
torch.Size([512, 999, 6, 9])
479520 snapshots
torch.Size([32, 6, 9])
converting























 97%|█████████▋| 467250/479520 [00:47<00:01, 11885.03it/s]
479520
rollout_GNN_GRU(
  (GRU): GRU(4, 128)
  (GNN): GNN_maker(
    (net): Sequential(
      (0): GNNlayer(
        (NN): Linear(in_features=128, out_features=128, bias=True)
      )
      (1): Tanh()
      (2): GNNlayer(
        (NN): Linear(in_features=128, out_features=4, bias=True)
      )
    )
  )
)
100%|██████████| 479520/479520 [00:48<00:00, 9869.57it/s]
  0%|          | 0/10 [00:00<?, ?it/s]




























































































































































































































































100%|█████████▉| 1684/1686 [08:26<00:00,  3.36it/s]
100%|██████████| 1686/1686 [08:27<00:00,  3.33it/s]












 98%|█████████▊| 185/188 [00:25<00:00,  7.26it/s]
Epoch: 1
LOSS: train: 0.157947 grad: 3.063584   |   test: 0.115092 grad: 3.128161
 10%|█         | 1/10 [08:52<1:19:56, 532.98s/it]





















































































































































































































































100%|██████████| 1686/1686 [08:13<00:00,  3.35it/s]
  0%|          | 0/188 [00:00<?, ?it/s]












 96%|█████████▌| 180/188 [00:24<00:01,  7.43it/s]
Epoch: 2
LOSS: train: 0.101161 grad: 3.016766   |   test: 0.092007 grad: 2.898984
 20%|██        | 2/10 [17:31<1:09:57, 524.74s/it]



































