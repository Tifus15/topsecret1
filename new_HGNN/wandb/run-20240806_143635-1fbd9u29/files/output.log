Config file content:
{'model': 'GAT', 'sob': [True, True], 'sob_a': [1.0, 1.0, 1.0], 'a': 0.01, 'opti': 'adamW', 'reg': 'none', 'loss': 'Huber', 'acts': ['tanh', None], 'epochs': 5, 'modelsize': 256, 'batchsize': 128, 'timesize': 32, 'lr': 0.001, 'split': 0.9, 'device': 'cpu', 'single': False, 'noloops': True, 'samples': 50}
5
torch.Size([128, 50, 1, 9])
50
torch.Size([32, 1, 8])
GNN_maker_HNN(
  (net): Sequential(
    (0): GATLayer(
      (fc): Linear(in_features=2, out_features=128, bias=False)
      (attn_fc): Linear(in_features=256, out_features=1, bias=False)
    )
    (1): Tanh()
    (2): GATLayer(
      (fc): Linear(in_features=128, out_features=6, bias=False)
      (attn_fc): Linear(in_features=12, out_features=1, bias=False)
    )
  )
)
TRAIN BATCHES : 33
TEST BATCHES : 3
TRAIN
  0%|                                                                                                                                                    | 0/5 [00:00<?, ?it/s]
































 97%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊    | 32/33 [02:51<00:05,  5.22s/it]
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 33/33 [02:56<00:00,  5.25s/it]


 67%|█████████████████████████████████████████████████████████████████████████████████████████████▎                                              | 2/3 [00:10<00:05,  5.19s/it]
Epoch: 1
LOSS: train: 29.562300   ham: 28.380629 |   test: 43.455200  ham: 42.281315
 20%|███████████████████████████▊                                                                                                               | 1/5 [03:11<12:47, 192.00s/it]
































 97%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊    | 32/33 [02:53<00:05,  5.42s/it]
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 33/33 [02:58<00:00,  5.30s/it]


 67%|█████████████████████████████████████████████████████████████████████████████████████████████▎                                              | 2/3 [00:10<00:05,  5.30s/it]
Epoch: 2
LOSS: train: 37.253990   ham: 36.025181 |   test: 27.229837  ham: 25.950006
 40%|███████████████████████████████████████████████████████▌                                                                                   | 2/5 [06:26<09:41, 193.71s/it]
































 97%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊    | 32/33 [02:49<00:05,  5.18s/it]
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 33/33 [02:54<00:00,  5.15s/it]


 60%|███████████████████████████████████████████████████████████████████████████████████▍                                                       | 3/5 [09:36<06:23, 191.62s/it]
  0%|                                                                                                                                                   | 0/33 [00:00<?, ?it/s]
Epoch: 3
LOSS: train: 31.960604   ham: 30.671335 |   test: 34.994160  ham: 33.694576
































 97%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊    | 32/33 [02:40<00:05,  5.04s/it]
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 33/33 [02:45<00:00,  5.04s/it]


 67%|█████████████████████████████████████████████████████████████████████████████████████████████▎                                              | 2/3 [00:09<00:04,  4.76s/it]
Epoch: 4
LOSS: train: 30.783594   ham: 29.460690 |   test: 33.733654  ham: 32.423222
 80%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                           | 4/5 [12:36<03:07, 187.21s/it]
































 97%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊    | 32/33 [02:40<00:05,  5.04s/it]
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 33/33 [02:45<00:00,  4.97s/it]


 67%|█████████████████████████████████████████████████████████████████████████████████████████████▎                                              | 2/3 [00:09<00:04,  4.72s/it]
Epoch: 5
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [15:35<00:00, 187.20s/it]
Traceback (most recent call last):
  File "/home/denis/Desktop/server-graph-models/new_HGNN/main_pend.py", line 947, in <module>
    metrics["train_grad_d4"] = container[1,epoch]
  File "/home/denis/Desktop/server-graph-models/new_HGNN/main_pend.py", line 506, in train2dof
    torch.save(model,"whole_model_dof2.pt")
  File "/home/denis/anaconda3/envs/dgl_hnn/lib/python3.9/site-packages/torch/serialization.py", line 628, in save
    _save(obj, opened_zipfile, pickle_module, pickle_protocol, _disable_byteorder_record)
  File "/home/denis/anaconda3/envs/dgl_hnn/lib/python3.9/site-packages/torch/serialization.py", line 840, in _save
    pickler.dump(obj)
AttributeError: Can't pickle local object 'TorchHistory.add_log_parameters_hook.<locals>.<lambda>'